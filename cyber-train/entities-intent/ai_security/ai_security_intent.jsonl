{"text": "I need to monitor AI model performance metrics for adversarial attacks and security indicators", "cats": {"MONITOR_AI_SECURITY": 1.0, "DETECT_ADVERSARIAL_ATTACKS": 1.0, "ANALYZE_METRICS": 1.0, "INVESTIGATE_INCIDENT": 0.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Please triage AI security alerts and investigate suspicious model behavior patterns", "cats": {"TRIAGE_ALERTS": 1.0, "INVESTIGATE_ANOMALIES": 1.0, "ANALYZE_BEHAVIOR": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Execute automated AI security scans on all model deployments in CI/CD pipeline", "cats": {"SCAN_MODELS": 1.0, "AUTOMATE_SECURITY": 1.0, "VALIDATE_DEPLOYMENT": 1.0, "ENFORCE_CONTROLS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Monitor AI model runtime security and detect adversarial manipulation attempts", "cats": {"MONITOR_RUNTIME": 1.0, "DETECT_ADVERSARIAL_ATTACKS": 1.0, "ANALYZE_SECURITY": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Review AI model access permissions and validate least privilege access controls", "cats": {"REVIEW_ACCESS": 1.0, "VALIDATE_PERMISSIONS": 1.0, "MANAGE_ENTITLEMENTS": 1.0, "AUDIT_COMPLIANCE": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Validate AI data security and privacy controls for GDPR compliance", "cats": {"VALIDATE_DATA_SECURITY": 1.0, "ENSURE_PRIVACY": 1.0, "AUDIT_COMPLIANCE": 1.0, "CHECK_LEAKAGE": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Patch AI model dependencies and apply security updates to ML frameworks", "cats": {"PATCH_DEPENDENCIES": 1.0, "UPDATE_SECURITY": 1.0, "MAINTAIN_SYSTEMS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Conduct AI security baseline assessments across all production models", "cats": {"ASSESS_SECURITY": 1.0, "VALIDATE_CONTROLS": 1.0, "IDENTIFY_VULNERABILITIES": 1.0, "AUDIT_COMPLIANCE": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Run comprehensive AI compliance scans for GDPR, CCPA, and EU AI Act", "cats": {"SCAN_COMPLIANCE": 1.0, "AUDIT_COMPLIANCE": 1.0, "VALIDATE_REGULATIONS": 1.0, "GENERATE_REPORTS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Simulate AI security incidents and test incident response procedures", "cats": {"SIMULATE_INCIDENTS": 1.0, "TEST_RESPONSE": 1.0, "VALIDATE_PROCEDURES": 1.0, "IMPROVE_PROCESSES": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Validate AI model encryption and key management security controls", "cats": {"VALIDATE_ENCRYPTION": 1.0, "CHECK_KEY_MANAGEMENT": 1.0, "ENSURE_PROTECTION": 1.0, "AUDIT_COMPLIANCE": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Analyze AI model usage patterns and identify security anomalies", "cats": {"ANALYZE_USAGE": 1.0, "DETECT_ANOMALIES": 1.0, "INVESTIGATE_PATTERNS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Execute comprehensive AI red team exercises against production systems", "cats": {"RED_TEAM_TESTING": 1.0, "TEST_VULNERABILITIES": 1.0, "SIMULATE_ATTACKS": 1.0, "IMPROVE_DEFENSES": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Audit AI supply chain security and assess dependency vulnerabilities", "cats": {"AUDIT_SUPPLY_CHAIN": 1.0, "ASSESS_DEPENDENCIES": 1.0, "IDENTIFY_VULNERABILITIES": 1.0, "MANAGE_RISKS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Test AI model backup and recovery procedures for disaster scenarios", "cats": {"TEST_BACKUP": 1.0, "VALIDATE_RECOVERY": 1.0, "ENSURE_CONTINUITY": 1.0, "MAINTAIN_SYSTEMS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Update AI security baselines and deploy enhanced protection controls", "cats": {"UPDATE_BASELINES": 1.0, "DEPLOY_CONTROLS": 1.0, "IMPROVE_SECURITY": 1.0, "MAINTAIN_SYSTEMS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Refresh AI security strategy and align with industry best practices", "cats": {"DEFINE_STRATEGY": 1.0, "ALIGN_STANDARDS": 1.0, "UPDATE_ARCHITECTURE": 1.0, "PLAN_INITIATIVES": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Engage third-party auditors for comprehensive AI security assessment", "cats": {"MANAGE_AUDITS": 1.0, "VALIDATE_COMPLIANCE": 1.0, "REVIEW_CONTROLS": 1.0, "PREPARE_REPORTS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Evaluate AI security platform vendors and assess tool effectiveness", "cats": {"EVALUATE_VENDORS": 1.0, "ASSESS_TOOLS": 1.0, "REVIEW_CAPABILITIES": 1.0, "MAKE_RECOMMENDATIONS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Execute enterprise-wide AI security simulation with coordinated attacks", "cats": {"SIMULATE_ATTACKS": 1.0, "TEST_COORDINATION": 1.0, "VALIDATE_DEFENSES": 1.0, "IMPROVE_SECURITY": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Define enterprise AI security policy aligned with NIST AI RMF framework", "cats": {"DEFINE_POLICY": 1.0, "ALIGN_FRAMEWORKS": 1.0, "ESTABLISH_CONTROLS": 1.0, "MAP_REQUIREMENTS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Run adversarial simulations including prompt injection and evasion attacks", "cats": {"SIMULATE_ATTACKS": 1.0, "TEST_ADVERSARIAL": 1.0, "DOCUMENT_VULNERABILITIES": 1.0, "IMPROVE_DEFENSES": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Monitor AI and LLM logs for prompt injection attempts using Guardrails", "cats": {"MONITOR_LOGS": 1.0, "DETECT_INJECTION": 1.0, "ANALYZE_PATTERNS": 1.0, "BLOCK_ATTEMPTS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Run fairness audits using AI Fairness 360 and generate bias metrics", "cats": {"AUDIT_FAIRNESS": 1.0, "DETECT_BIAS": 1.0, "GENERATE_METRICS": 1.0, "REMEDIATE_ISSUES": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Generate model cards for deployed models with architecture and limitations", "cats": {"GENERATE_DOCUMENTATION": 1.0, "DOCUMENT_MODELS": 1.0, "CAPTURE_METADATA": 1.0, "AUDIT_COMPLIANCE": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Validate explainability of model outputs using SHAP and LIME tools", "cats": {"VALIDATE_EXPLAINABILITY": 1.0, "ASSESS_TRANSPARENCY": 1.0, "GENERATE_EXPLANATIONS": 1.0, "AUDIT_COMPLIANCE": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Monitor model drift and compare inference distribution to training baseline", "cats": {"MONITOR_DRIFT": 1.0, "ANALYZE_DISTRIBUTION": 1.0, "DETECT_DEGRADATION": 1.0, "RECOMMEND_RETRAINING": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Assess third-party AI vendors for compliance with AI Act standards", "cats": {"ASSESS_VENDORS": 1.0, "VALIDATE_COMPLIANCE": 1.0, "REVIEW_STANDARDS": 1.0, "MANAGE_RISKS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Respond to AI security incident involving model theft and data leakage", "cats": {"RESPOND_TO_INCIDENT": 1.0, "CONTAIN_BREACH": 1.0, "INVESTIGATE_ATTACK": 1.0, "RECOVER_SYSTEMS": 1.0, "AUDIT_COMPLIANCE": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Audit AI systems for privacy compliance using Presidio and PrivacyRaven", "cats": {"AUDIT_PRIVACY": 1.0, "VALIDATE_COMPLIANCE": 1.0, "CHECK_PII_EXPOSURE": 1.0, "ENSURE_DSAR_HANDLING": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Test models in AI safety sandbox before production release", "cats": {"TEST_SAFETY": 1.0, "VALIDATE_MODELS": 1.0, "ASSESS_RISKS": 1.0, "APPROVE_DEPLOYMENT": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "I need to investigate why the GPT-4 model is showing unusual response patterns", "cats": {"INVESTIGATE_ANOMALIES": 1.0, "ANALYZE_BEHAVIOR": 1.0, "DETECT_ANOMALIES": 1.0, "RESPOND_TO_INCIDENT": 0.5, "MONITOR_AI_SECURITY": 1.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Please block all prompt injection attempts detected on the Claude API endpoint", "cats": {"BLOCK_ATTACKS": 1.0, "RESPOND_TO_INCIDENT": 1.0, "ENFORCE_CONTROLS": 1.0, "DETECT_INJECTION": 1.0, "AUDIT_COMPLIANCE": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Generate compliance report showing AI model adherence to EU AI Act requirements", "cats": {"GENERATE_REPORTS": 1.0, "AUDIT_COMPLIANCE": 1.0, "VALIDATE_REGULATIONS": 1.0, "DOCUMENT_COMPLIANCE": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Isolate compromised AI model and revoke access credentials immediately", "cats": {"RESPOND_TO_INCIDENT": 1.0, "CONTAIN_BREACH": 1.0, "ISOLATE_SYSTEMS": 1.0, "REVOKE_ACCESS": 1.0, "AUDIT_COMPLIANCE": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Restore AI model from secure backup and patch identified vulnerabilities", "cats": {"RECOVER_SYSTEMS": 1.0, "RESTORE_BACKUP": 1.0, "PATCH_VULNERABILITIES": 1.0, "RESPOND_TO_INCIDENT": 1.0, "AUDIT_COMPLIANCE": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Remove poisoned data from training dataset and implement validation controls", "cats": {"REMEDIATE_ISSUES": 1.0, "CLEAN_DATA": 1.0, "IMPLEMENT_CONTROLS": 1.0, "RESPOND_TO_INCIDENT": 1.0, "AUDIT_COMPLIANCE": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Retrain AI model with clean validated data and test security improvements", "cats": {"RETRAIN_MODELS": 1.0, "VALIDATE_DATA": 1.0, "TEST_SECURITY": 1.0, "IMPROVE_DEFENSES": 1.0, "RESPOND_TO_INCIDENT": 0.5, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Update AI model security controls and implement additional protection measures", "cats": {"UPDATE_CONTROLS": 1.0, "IMPLEMENT_PROTECTION": 1.0, "IMPROVE_SECURITY": 1.0, "MAINTAIN_SYSTEMS": 1.0, "RESPOND_TO_INCIDENT": 0.5, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Document AI security incident and capture lessons learned for process improvement", "cats": {"DOCUMENT_INCIDENT": 1.0, "CAPTURE_LEARNINGS": 1.0, "IMPROVE_PROCESSES": 1.0, "RESPOND_TO_INCIDENT": 1.0, "AUDIT_COMPLIANCE": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Deploy AI security scanning across all models and test for adversarial vulnerabilities", "cats": {"SCAN_MODELS": 1.0, "TEST_VULNERABILITIES": 1.0, "VALIDATE_CONTROLS": 1.0, "IMPROVE_DEFENSES": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Execute adversarial attacks against AI models to test robustness and defenses", "cats": {"TEST_ADVERSARIAL": 1.0, "SIMULATE_ATTACKS": 1.0, "VALIDATE_DEFENSES": 1.0, "IMPROVE_SECURITY": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Assess AI training data security and validate privacy protection measures", "cats": {"ASSESS_DATA_SECURITY": 1.0, "VALIDATE_PRIVACY": 1.0, "CHECK_ENCRYPTION": 1.0, "AUDIT_COMPLIANCE": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Ensure GDPR and CCPA compliance for AI systems processing personal data", "cats": {"ENSURE_COMPLIANCE": 1.0, "VALIDATE_REGULATIONS": 1.0, "AUDIT_COMPLIANCE": 1.0, "IMPLEMENT_CONTROLS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Implement data anonymization and pseudonymization for AI training datasets", "cats": {"IMPLEMENT_PRIVACY": 1.0, "ANONYMIZE_DATA": 1.0, "PROTECT_PII": 1.0, "AUDIT_COMPLIANCE": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Implement AI model governance frameworks and establish ethics practices", "cats": {"IMPLEMENT_GOVERNANCE": 1.0, "ESTABLISH_ETHICS": 1.0, "DEFINE_POLICY": 1.0, "AUDIT_COMPLIANCE": 1.0, "RESPOND_TO_INCIDENT": 0.0, "MONITOR_AI_SECURITY": 0.0}}
{"text": "Monitor AI bias and fairness metrics to ensure responsible AI practices", "cats": {"MONITOR_BIAS": 1.0, "ASSESS_FAIRNESS": 1.0, "ENSURE_ETHICS": 1.0, "AUDIT_COMPLIANCE": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Validate AI ethics and responsible AI practices across production systems", "cats": {"VALIDATE_ETHICS": 1.0, "ASSESS_PRACTICES": 1.0, "AUDIT_COMPLIANCE": 1.0, "ENSURE_RESPONSIBILITY": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Monitor AI security alerts and detect model manipulation attempts in real-time", "cats": {"MONITOR_ALERTS": 1.0, "DETECT_MANIPULATION": 1.0, "ANALYZE_SECURITY": 1.0, "RESPOND_TO_INCIDENT": 0.5, "AUDIT_COMPLIANCE": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Review AI system access logs for unauthorized model access attempts", "cats": {"REVIEW_LOGS": 1.0, "CHECK_ACCESS": 1.0, "DETECT_UNAUTHORIZED": 1.0, "RESPOND_TO_INCIDENT": 0.5, "AUDIT_COMPLIANCE": 1.0, "DEFINE_POLICY": 0.0}}
{"text": "Validate AI security alert accuracy and reduce false positive noise", "cats": {"VALIDATE_ALERTS": 1.0, "REDUCE_FALSE_POSITIVES": 1.0, "IMPROVE_ACCURACY": 1.0, "OPTIMIZE_MONITORING": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Check for data drift and model degradation in production AI systems", "cats": {"CHECK_DRIFT": 1.0, "DETECT_DEGRADATION": 1.0, "MONITOR_PERFORMANCE": 1.0, "ANALYZE_METRICS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Evaluate AI component security and assess dependency vulnerability management", "cats": {"EVALUATE_COMPONENTS": 1.0, "ASSESS_DEPENDENCIES": 1.0, "MANAGE_VULNERABILITIES": 1.0, "AUDIT_SUPPLY_CHAIN": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Review AI framework security and validate dependency management processes", "cats": {"REVIEW_FRAMEWORKS": 1.0, "VALIDATE_DEPENDENCIES": 1.0, "ASSESS_SECURITY": 1.0, "AUDIT_SUPPLY_CHAIN": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Document AI supply chain risk ratings and create remediation plans", "cats": {"DOCUMENT_RISKS": 1.0, "RATE_SUPPLY_CHAIN": 1.0, "CREATE_PLANS": 1.0, "MANAGE_RISKS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Test AI model versioning and validate rollback capabilities", "cats": {"TEST_VERSIONING": 1.0, "VALIDATE_ROLLBACK": 1.0, "ENSURE_RECOVERY": 1.0, "MAINTAIN_SYSTEMS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Simulate AI model failure scenarios and test recovery procedures", "cats": {"SIMULATE_FAILURES": 1.0, "TEST_RECOVERY": 1.0, "VALIDATE_PROCEDURES": 1.0, "ENSURE_CONTINUITY": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Document AI model backup and recovery procedures for disaster scenarios", "cats": {"DOCUMENT_PROCEDURES": 1.0, "CAPTURE_BACKUP": 1.0, "ENSURE_RECOVERY": 1.0, "MAINTAIN_SYSTEMS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Update AI security policies and validate compliance requirements", "cats": {"UPDATE_POLICIES": 1.0, "VALIDATE_COMPLIANCE": 1.0, "DEFINE_POLICY": 1.0, "AUDIT_COMPLIANCE": 1.0, "RESPOND_TO_INCIDENT": 0.0, "MONITOR_AI_SECURITY": 0.0}}
{"text": "Test AI security controls and validate model protection measures", "cats": {"TEST_CONTROLS": 1.0, "VALIDATE_PROTECTION": 1.0, "ASSESS_SECURITY": 1.0, "IMPROVE_DEFENSES": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Deploy updated AI security controls across all enterprise AI systems", "cats": {"DEPLOY_CONTROLS": 1.0, "UPDATE_SECURITY": 1.0, "MAINTAIN_SYSTEMS": 1.0, "IMPROVE_SECURITY": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Update AI security strategy based on latest threats and emerging technologies", "cats": {"UPDATE_STRATEGY": 1.0, "ASSESS_THREATS": 1.0, "EVALUATE_TECHNOLOGIES": 1.0, "DEFINE_POLICY": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Align AI security controls with industry standards and best practices", "cats": {"ALIGN_STANDARDS": 1.0, "FOLLOW_BEST_PRACTICES": 1.0, "UPDATE_CONTROLS": 1.0, "DEFINE_POLICY": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Review and update AI security architecture and design principles", "cats": {"REVIEW_ARCHITECTURE": 1.0, "UPDATE_DESIGN": 1.0, "DEFINE_POLICY": 1.0, "IMPROVE_SECURITY": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Document strategic AI security initiatives and investment priorities", "cats": {"DOCUMENT_INITIATIVES": 1.0, "PLAN_INVESTMENTS": 1.0, "DEFINE_POLICY": 1.0, "STRATEGIC_PLANNING": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Validate compliance with AI regulations and industry standards", "cats": {"VALIDATE_COMPLIANCE": 1.0, "CHECK_REGULATIONS": 1.0, "AUDIT_COMPLIANCE": 1.0, "REVIEW_STANDARDS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Review AI security controls and governance frameworks", "cats": {"REVIEW_CONTROLS": 1.0, "ASSESS_GOVERNANCE": 1.0, "AUDIT_COMPLIANCE": 1.0, "VALIDATE_FRAMEWORKS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Prepare AI security audit reports and remediation plans", "cats": {"PREPARE_REPORTS": 1.0, "DOCUMENT_AUDITS": 1.0, "CREATE_PLANS": 1.0, "AUDIT_COMPLIANCE": 1.0, "RESPOND_TO_INCIDENT": 0.0, "DEFINE_POLICY": 0.0}}
{"text": "Assess AI security tool effectiveness and integration capabilities", "cats": {"ASSESS_TOOLS": 1.0, "EVALUATE_EFFECTIVENESS": 1.0, "REVIEW_INTEGRATION": 1.0, "MAKE_RECOMMENDATIONS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Review AI security vendor postures and certifications", "cats": {"REVIEW_VENDORS": 1.0, "ASSESS_CERTIFICATIONS": 1.0, "EVALUATE_VENDORS": 1.0, "MANAGE_RISKS": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Make recommendations for AI security platform investments", "cats": {"MAKE_RECOMMENDATIONS": 1.0, "EVALUATE_INVESTMENTS": 1.0, "PLAN_INITIATIVES": 1.0, "STRATEGIC_PLANNING": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Test coordinated attacks across multiple AI systems and infrastructure", "cats": {"TEST_COORDINATION": 1.0, "SIMULATE_ATTACKS": 1.0, "VALIDATE_DEFENSES": 1.0, "IMPROVE_SECURITY": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Simulate AI supply chain attacks and model dependency compromises", "cats": {"SIMULATE_ATTACKS": 1.0, "TEST_SUPPLY_CHAIN": 1.0, "VALIDATE_DEFENSES": 1.0, "IMPROVE_SECURITY": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}
{"text": "Document lessons learned and AI security improvements from simulation", "cats": {"DOCUMENT_LEARNINGS": 1.0, "CAPTURE_IMPROVEMENTS": 1.0, "IMPROVE_PROCESSES": 1.0, "ENHANCE_SECURITY": 1.0, "RESPOND_TO_INCIDENT": 0.0, "AUDIT_COMPLIANCE": 0.0}}

